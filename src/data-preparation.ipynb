{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the features of a malicious URL\n",
    "\n",
    "Based on a [study by the University of Huddersfield in the United Kingdom](https://eprints.hud.ac.uk/id/eprint/24330/6/MohammadPhishing14July2015.pdf), certain URL characteristics can signal a potential phishing website:\n",
    "\n",
    "| Indicator              | Description                                                                                           |\n",
    "|------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| `IP Address Usage`       | Legitimate websites primarily use domain names. The presence of a raw IP address suggests an attempt to mask the site's true identity. |\n",
    "| `Extended URL Length`    | Phishers craft long URLs to obscure the suspicious parts of the address, making the site harder to scrutinize. |\n",
    "| `URL Shortening`         | Shortened links hide the full, potentially malicious, domain name.                                      |\n",
    "| `'@' Symbol Inclusion`   | The \"@\" symbol tricks browsers into ignoring the initial part of the URL and redirects to a different website hidden behind the symbol. |\n",
    "| `Multiple '//' Symbols`  | The presence of extra \"//\" within a URL indicates redirection to a different website, which is a common phishing tactic. |\n",
    "| `Excessive Dots in Domain`  | A URL with more than two dots between the initial 'www' and the country-code Top-Level Domain (e.g., .sg, .uk, .ca) is suspicious, as it may reveal a multitude of nested subdomains. |\n",
    "| `Lack of HTTPS`          | The absence of the secure HTTPS protocol can be a red flag, as legitimate sites often use HTTPS to ensure secure connections. |\n",
    "| `Domain Dashes` | Phishers frequently insert prefixes or suffixes separated by dashes into domain names, making them appear legitimate to unsuspecting users. |\n",
    "\n",
    "<br>\n",
    "\n",
    "Additionally, our dataset includes non-URL based features that the study has identified as good indicators of potential phishing websites as well:\n",
    "| Indicator          | Description                                                                                                  |\n",
    "|--------------------|--------------------------------------------------------------------------------------------------------------|\n",
    "| `Google-Index`       | Phishing sites are often newly registered and may not be indexed by the Google Search Engine.  |\n",
    "| `Age of Domain`      | Unlike legitimate websites that often have long-established domains, phishing sites tend to use newly registered domains and disappear quickly. |\n",
    "| `Domain Expiration`  | Similarly, legitimate domains are often renewed for extended periods, while phishing domains may have short expiration windows.    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the following features of the dataset are selected:\n",
    "-   URL Characteristics:\n",
    "    -   `domain_in_ip`: Domain in IP.\n",
    "    -   `length_url`: Length of the URL.\n",
    "    -   `url_shortened`: URL shortened.\n",
    "    -   `qty_at_url`: Quantity of \"@\" symbols in the URL.\n",
    "    -   `qty_dot_domain`: Quantity of dots in the domain.\n",
    "    -   `tls_ssl_certificate`: TLS SSL certificate.\n",
    "    -   `qty_hyphen_domain`: Quantity of hyphens in the domain.\n",
    "- Non-URL Characteristics:\n",
    "    -   `url_google_index`: URL Google index.\n",
    "    -   `domain_google_index`: Domain Google index.\n",
    "    -   `time_domain_activation`: Time domain activation.\n",
    "    -   `time_domain_expiration`: Time domain expiration.\n",
    "\n",
    "We decided to exclude the `Multiple '//' Symbols` feature from our analysis. This is because our dataset tracks the number of single '/' symbols, which can be quite common in legitimate URLs for directories and file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Collecting the Data\n",
    "\n",
    "We will leverage two key datasets for this project:\n",
    "\n",
    "1. [Phishing Domain URL Dataset](https://www.kaggle.com/datasets/michellevp/dataset-phishing-domain-detection-cybersecurity) \n",
    "    - This dataset offers a rich array of URL-derived features, specifically tailored for detecting phishing domains.\n",
    "2. [Malicious URLs Dataset](https://www.kaggle.com/datasets/sid321axn/malicious-urls-dataset)\n",
    "    - This dataset provides a broad selection of both malicious and safe website URLs.\n",
    "\n",
    "**Focus**: As the `Malicious URLs Dataset` also contains URLs to other forms of malicious websites, we will filter this dataset to isolate only phishing-related and benign URLs.\n",
    "\n",
    "**Data Sampling**: Due to the size of these datasets, we will select 1000 entries from each. This approach ensures a manageable dataset while maintaining diversity for effective analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the datasets\n",
    "import pandas as pd\n",
    "url_information = pd.read_csv('../datasets/url_information.csv')\n",
    "malicious_urls = pd.read_csv('../datasets/malicious_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Malicious URLs Dataset\n",
    "filtered_malicious_urls = malicious_urls[malicious_urls['type'].isin(['phishing', 'benign'])]\n",
    "sampled_malicious_urls = filtered_malicious_urls.sample(n=1000, replace=False, random_state=69)\n",
    "\n",
    "# Filtering URL Information Dataset\n",
    "selected_columns = [\n",
    "    'domain_in_ip', 'length_url', 'url_shortened', 'qty_at_url', 'qty_dot_domain', \n",
    "    'tls_ssl_certificate', 'qty_hyphen_domain', 'url_google_index', 'domain_google_index', \n",
    "    'time_domain_activation', 'time_domain_expiration', 'phishing'\n",
    "]\n",
    "filtered_url_information = url_information[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visual observation and preliminary analysis of our dataset, it seems to have a low representation of non-null values in the columns `domain_in_ip`, `url_shortened`, `qty_at_url`, `url_google_index`, and `domain_google_index`. To improve data quality and avoid disproportionate representation, we wil perform the following steps: \n",
    "\n",
    "1. **Targeted Sampling**:  Randomly select 500 samples where **at least** one these columns have non-null values, with no duplicate entries.\n",
    "\n",
    "2. **General Sampling**: The remaining 500 entries will be randomly chosen from the entire dataset, with no duplicates entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_in_ip</th>\n",
       "      <th>length_url</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_dot_domain</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_hyphen_domain</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>time_domain_activation</th>\n",
       "      <th>time_domain_expiration</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1640</td>\n",
       "      <td>551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5355</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7865</td>\n",
       "      <td>1631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain_in_ip  length_url  url_shortened  qty_at_url  qty_dot_domain  \\\n",
       "0             0          13              0           0               1   \n",
       "1             0         329              0           0               2   \n",
       "2             0          24              0           0               2   \n",
       "3             0          23              0           0               1   \n",
       "4             0          23              0           0               2   \n",
       "5             0          22              0           0               3   \n",
       "6             0         143              0           0               2   \n",
       "7             0          33              0           0               2   \n",
       "8             0          17              0           0               2   \n",
       "9             0          35              0           0               1   \n",
       "\n",
       "   tls_ssl_certificate  qty_hyphen_domain  url_google_index  \\\n",
       "0                    0                  0                 0   \n",
       "1                    0                  0                 0   \n",
       "2                    1                  0                 0   \n",
       "3                    0                  1                 0   \n",
       "4                    1                  1                 0   \n",
       "5                    0                  0                 0   \n",
       "6                    1                  1                 0   \n",
       "7                    1                  0                 0   \n",
       "8                    0                  0                 0   \n",
       "9                    1                  0                 0   \n",
       "\n",
       "   domain_google_index  time_domain_activation  time_domain_expiration  \\\n",
       "0                    0                    1640                     551   \n",
       "1                    0                      -1                      -1   \n",
       "2                    0                    5355                     123   \n",
       "3                    0                      -1                      -1   \n",
       "4                    0                    7865                    1631   \n",
       "5                    0                      -1                      -1   \n",
       "6                    0                      -1                      -1   \n",
       "7                    0                      -1                      -1   \n",
       "8                    0                    1062                      33   \n",
       "9                    0                       3                     361   \n",
       "\n",
       "   phishing  \n",
       "0         1  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  \n",
       "5         0  \n",
       "6         1  \n",
       "7         1  \n",
       "8         0  \n",
       "9         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe that the first 10 entries have all 0s in the columns `domain_in_ip`, `url_shortened`, `qty_at_url`, `qty_underline_domain`, `url_google_index`, and `domain_google_index`\n",
    "filtered_url_information.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain_in_ip           0.997309\n",
      "url_shortened          0.993631\n",
      "qty_at_url             0.977532\n",
      "url_google_index       0.997217\n",
      "domain_google_index    0.996577\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We can also calculate the proportion of 0s as a fraction of the total entries, and observe that around 97-99% of the entire column are actually null values\n",
    "columns_to_check = ['domain_in_ip', 'url_shortened', 'qty_at_url', 'url_google_index', 'domain_google_index']\n",
    "proportion_zeros = filtered_url_information[columns_to_check].apply(lambda x: (x == 0).sum() / len(x))\n",
    "print(proportion_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the 1000 samples\n",
    "sampled_url_information = pd.DataFrame()  # Dataframe to store our final samples\n",
    "targeted_url_information = pd.DataFrame()  # Dataframe for entries with non-zero target columns\n",
    "\n",
    "# Iterate over the underrepresented columns, and select all non-null entries\n",
    "for column in columns_to_check:\n",
    "    available_entries = filtered_url_information[(filtered_url_information[column] != 0)]  # Filter for rows with non-zero values in the current column\n",
    "    targeted_url_information = pd.concat([targeted_url_information, available_entries])  # Add valid entries to our targeted dataframe\n",
    "\n",
    "# Remove duplicates, ensuring we keep entries with at least one non-null target column \n",
    "targeted_url_information = targeted_url_information.drop_duplicates()\n",
    "targeted_samples = targeted_url_information.sample(n=500, replace=False, random_state=69)  # Randomly select 500 from the targeted entries\n",
    "\n",
    "# Add the 500 targeted samples to the main sample dataframe\n",
    "sampled_url_information = pd.concat([sampled_url_information, targeted_samples])\n",
    "\n",
    "# I know that this method is a bit monkey-brained, but my original method did not work (see below)\n",
    "r = 1\n",
    "while len(sampled_url_information.drop_duplicates()) < 1000:\n",
    "    general_sample = filtered_url_information.sample(n=1, replace=False, random_state=r)  # Take a single random sample\n",
    "    sampled_url_information = pd.concat([sampled_url_information, general_sample])  # Add it to the main dataframe\n",
    "    r = r + 1\n",
    "\n",
    "sampled_url_information = sampled_url_information.drop_duplicates()  # Ensure all entries are unique \n",
    "\n",
    "\n",
    "# My original method was to filter based on indices: locate all entries which are found in filtered_url_information but not found in targeted_samples (non-duplicates)\n",
    "# However, there were always duplicates, and I could never get a final dataframe of 1000 entries.\n",
    "\n",
    "# general_url_information = pd.DataFrame()\n",
    "# general_url_information = filtered_url_information.loc[~filtered_url_information.index.isin(targeted_samples.index)]\n",
    "# general_samples = general_url_information.sample(n=500, replace=False, random_state=69)\n",
    "# sampled_url_information = pd.concat([targeted_samples, general_samples]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain_in_ip           0.962\n",
      "url_shortened          0.960\n",
      "qty_at_url             0.657\n",
      "url_google_index       0.938\n",
      "domain_google_index    0.928\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We can re-calculate the proportion of 0s and observe a slight improvement!\n",
    "proportion_zeros = sampled_url_information[columns_to_check].apply(lambda x: (x == 0).sum() / len(x))\n",
    "print(proportion_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write to a new CSV\n",
    "filtered_malicious_urls.to_csv('../datasets/filtered_malicious_urls.csv', index=False)\n",
    "sampled_malicious_urls.to_csv('../datasets/sampled_malicious_urls.csv', index=False)\n",
    "sampled_url_information.to_csv('../datasets/sampled_url_information.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
